{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Tennis\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import config\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ddpg import DDPGAgent\n",
    "# from config import Config\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "from utilities import ReplayBuffer\n",
    "# from agent.maddpg import MADDPG, MultiAgentConfig\n",
    "# from IPython.display import clear_output\n",
    "# from unityagents import UnityEnvironment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/home/maurice/Documents/udacity_new/data/Tennis_Linux_NoVis/Tennis.x86_64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default environment parameters\n",
    "brain_name  = env.brain_names[0]\n",
    "brain       = env.brains[brain_name]\n",
    "env_info    = env.reset(train_mode=True)[brain_name]\n",
    "num_agents  = len(env_info.agents)\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size  = env_info.vector_observations.shape[1]\n",
    "\n",
    "# state = env_info.vector_observations\n",
    "\n",
    "# print(action_size, state_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_to_tensor(input_list):\n",
    "    make_tensor = lambda x: torch.tensor(x, dtype=torch.float)\n",
    "    return list(map(make_tensor, zip(*input_list)))\n",
    "\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MADDPG():\n",
    "    def __init__(self, state_size, action_size, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.seed   = config.seed \n",
    "        self.agents = [DDPGAgent(state_size, action_size, self.config) for _ in range(num_agents)]\n",
    "        self.iter   = 0 \n",
    "        self.learn_iter = 0\n",
    "        \n",
    "        self.beta_function = lambda x: min(1.0, self.config.beta + x * (1.0 - self.config.beta) / self.config.beta_decay)\n",
    "        self.memory = ReplayBuffer(self.config.buffer_size, self.config.seed)\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        for ddpg_agent in self.agents:\n",
    "            ddpg_agent.reset()\n",
    "    \n",
    "    def get_actors(self):\n",
    "        \"\"\"get actors of all the agents in the MADDPG object\"\"\"\n",
    "        actors = [ddpg_agent.actor for ddpg_agent in self.agents]\n",
    "        return actors\n",
    "    \n",
    "    \n",
    "    def get_target_actors(self):\n",
    "        \"\"\"get target_actors of all the agents in the MADDPG object\"\"\"\n",
    "        target_actors = [ddpg_agent.target_actor for ddpg_agent in self.agents]\n",
    "        return target_actors\n",
    "    \n",
    "    \n",
    "    def act(self, obs_all_agents, noise=0.0):\n",
    "        \"\"\"get actions from all agents in the MADDPG object\"\"\"\n",
    "        obs_all_agents = torch.tensor(obs_all_agents, dtype=torch.float).to(self.config.device)\n",
    "        actions = [np.clip(agent.act(obs, noise).cpu().data.numpy(), -1, 1) \n",
    "                   for agent, obs in zip(self.agents, obs_all_agents)]\n",
    "        return actions\n",
    "    \n",
    "    \n",
    "    def target_act(self, obs_all_agents, noise=0.0):\n",
    "        \"\"\"get target network actions from all the agents in the MADDPG object \"\"\"\n",
    "        target_actions = [ddpg_agent.target_act(obs, noise) for ddpg_agent, obs \n",
    "                          in zip(self.agents, obs_all_agents)]\n",
    "        return target_actions\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        self.memory.push(state, action, reward, next_state, done)\n",
    "        self.iter += 1\n",
    "\n",
    "        if(len(self.memory) >= self.config.batch_size) and self.iter % self.config.update_every == 0:\n",
    "            beta = self.beta_function(self.learn_iter)\n",
    "            for i in range(len(self.agents)):\n",
    "                samples = self.memory.sample(self.config.batch_size, beta)\n",
    "                self.update(samples, i)\n",
    "            self.learn_iter += 1\n",
    "            self.update_targets()\n",
    "\n",
    "    def _prep_samples(self, samples):\n",
    "        convert = lambda x: torch.tensor(x, dtype=torch.float).to(self.config.device)\n",
    "\n",
    "        obs, action, reward, next_obs, done, weights, idx = samples\n",
    "\n",
    "        obs           = np.rollaxis(obs, 1)\n",
    "        next_obs      = np.rollaxis(next_obs, 1)\n",
    "        obs_full      = np.hstack(obs)\n",
    "        next_obs_full = np.hstack(next_obs)\n",
    "\n",
    "        obs           = convert(obs)\n",
    "        obs_full      = convert(obs_full)\n",
    "        action        = convert(action)\n",
    "        reward        = convert(reward)\n",
    "        next_obs      = convert(next_obs)\n",
    "        next_obs_full = convert(next_obs_full)\n",
    "        done          = convert(np.float32(done))\n",
    "        weights       = convert(weights)\n",
    "\n",
    "        return obs, obs_full, action, reward, next_obs, next_obs_full, done, idx, weights            \n",
    "    \n",
    "    def update(self, samples, agent_number):\n",
    "        \"\"\"update the critics and actors of all the agents \"\"\"\n",
    "\n",
    "        # need to transpose each element of the samples\n",
    "        # to flip obs[parallel_agent][agent_number] to\n",
    "        # obs[agent_number][parallel_agent]\n",
    "        \n",
    "        \n",
    "        obs, obs_full, action, reward, next_obs, next_obs_full, done, idx, weights = self._prep_samples(samples)        \n",
    "#         obs, obs_full, action, reward, next_obs, next_obs_full, done = map(transpose_to_tensor, samples)\n",
    "\n",
    "#         obs_full = torch.stack(obs_full)\n",
    "#         next_obs_full = torch.stack(next_obs_full)\n",
    "        \n",
    "        agent = self.agents[agent_number]\n",
    "        agent.critic_optimizer.zero_grad()\n",
    "\n",
    "        #critic loss = batch mean of (y- Q(s,a) from target network)^2\n",
    "        #y = reward of this timestep + discount * Q(st+1,at+1) from target network\n",
    "        target_actions = self.target_act(next_obs)\n",
    "        target_actions = torch.cat(target_actions, dim=1).detach()\n",
    "        \n",
    "        target_critic_input = torch.cat((next_obs_full,target_actions), dim=1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            q_next = agent.target_critic(target_critic_input)\n",
    "        \n",
    "        \n",
    "#         print('\\ncheck A = ', reward[agent_number].view(-1, 1))\n",
    "#         print('check B = ', self.config.gamma)\n",
    "#         print('check C = ', q_next)\n",
    "#         print('check D = ', 1 - done[agent_number].view(-1, 1))\n",
    "        \n",
    "#         y = reward[agent_number].view(-1, 1) + self.config.gamma * q_next * (1 - done[agent_number].view(-1, 1))\n",
    "        y = reward[..., agent_number].unsqueeze(1) + self.config.gamma * q_next * (1 - done[..., agent_number].unsqueeze(1))\n",
    "        \n",
    "#         action = torch.cat(action, dim=1)?\n",
    "        critic_input = torch.cat((obs_full, action.view(self.config.batch_size, -1)), dim=1)\n",
    "        q = agent.critic(critic_input)\n",
    "\n",
    "        huber_loss = torch.nn.SmoothL1Loss()\n",
    "        critic_loss = huber_loss(q, y.detach())\n",
    "        critic_loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(agent.critic.parameters(), 0.5)\n",
    "        agent.critic_optimizer.step()\n",
    "\n",
    "        #update actor network using policy gradient\n",
    "        agent.actor_optimizer.zero_grad()\n",
    "        # make input to agent\n",
    "        # detach the other agents to save computation\n",
    "        # saves some time for computing derivative\n",
    "        q_input = [ self.agents[i].actor(ob) if i == agent_number \\\n",
    "                   else self.agents[i].actor(ob).detach()\n",
    "                   for i, ob in enumerate(obs) ]\n",
    "                \n",
    "        q_input = torch.cat(q_input, dim=1)\n",
    "        # combine all the actions and observations for input to critic\n",
    "        # many of the obs are redundant, and obs[1] contains all useful information already\n",
    "        q_input2 = torch.cat((obs_full, q_input), dim=1)\n",
    "        \n",
    "        # get the policy gradient\n",
    "        actor_loss = -agent.critic(q_input2).mean()\n",
    "        actor_loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(agent.actor.parameters(),0.5)\n",
    "        agent.actor_optimizer.step()\n",
    "\n",
    "        al = actor_loss.cpu().detach().item()\n",
    "        cl = critic_loss.cpu().detach().item()\n",
    "#         logger.add_scalars('agent%i/losses' % agent_number,\n",
    "#                            {'critic loss': cl,\n",
    "#                             'actor_loss': al},\n",
    "#                            self.iter)\n",
    "\n",
    "    def update_targets(self):\n",
    "        \"\"\"soft update targets\"\"\"\n",
    "        self.iter += 1\n",
    "        for ddpg_agent in self.agents:\n",
    "            soft_update(ddpg_agent.target_actor, ddpg_agent.actor, self.config.tau)\n",
    "            soft_update(ddpg_agent.target_critic, ddpg_agent.critic, self.config.tau)\n",
    "      \n",
    "    def save_checkpoints(self, file_head):\n",
    "        for i in range(len(self.agents)):\n",
    "            file_name = file_head + 'agent{}_'.format(i)\n",
    "            torch.save(self.agents[i].actor.state_dict(), file_name + '_actor.pth')\n",
    "            torch.save(self.agents[i].critic.state_dict(), file_name + '_critic.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(maddpg, n_eps=10000, max_steps=1000):\n",
    "    \n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    train_mode = True\n",
    "    \n",
    "    frame_num = 0\n",
    "    current_max = 1.0\n",
    "    \n",
    "    # training loop\n",
    "    for i_eps in range(n_eps):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "        state    = env_info.vector_observations\n",
    "        maddpg.reset()\n",
    "        agent_scores = np.zeros(num_agents)\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action     = maddpg.act(state, 1.0)\n",
    "            env_info   = env.step(action)[brain_name] \n",
    "            reward     = env_info.rewards\n",
    "            next_state = env_info.vector_observations\n",
    "            done       = env_info.local_done\n",
    "            maddpg.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            state      = next_state\n",
    "            agent_scores += reward\n",
    "            frame_num += 1\n",
    "            \n",
    "            if np.any(done): break\n",
    "                \n",
    "        max_score = np.max(agent_scores)\n",
    "        scores_window.append(max_score)\n",
    "        scores.append(max_score)                \n",
    "    \n",
    "        # change all these print statements    \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_eps, np.mean(scores_window)), end=\"\")\n",
    "        \n",
    "        if i_eps % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_eps, np.mean(scores_window)))\n",
    "\n",
    "#         if max_score > current_max:\n",
    "        if i_eps == 100:\n",
    "#             maddpg.save_checkpoints('/checkpoints/')\n",
    "            current_max = max_score\n",
    "            for i in range(len(maddpg.agents)):\n",
    "                torch.save(maddpg.agents[i].actor.state_dict(),  'checkpoints/actor'  + str(i) +'checkpoint.pth')\n",
    "                torch.save(maddpg.agents[i].critic.state_dict(), 'checkpoints/critic' + str(i) +'checkpoint.pth')\n",
    "\n",
    "                \n",
    "        if np.mean(scores_window) >= 0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_eps, np.mean(scores_window)))\n",
    "            break\n",
    "            \n",
    "            \n",
    "    return scores\n",
    "                \n",
    "    \n",
    "    \n",
    "def plot_scores(scores, title=\"\"):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(title)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\tAverage Score: 0.00\n",
      "Episode 100\tAverage Score: 0.01\n",
      "Episode 200\tAverage Score: 0.02\n",
      "Episode 300\tAverage Score: 0.02\n",
      "Episode 400\tAverage Score: 0.02\n",
      "Episode 500\tAverage Score: 0.05\n",
      "Episode 600\tAverage Score: 0.06\n",
      "Episode 700\tAverage Score: 0.07\n",
      "Episode 800\tAverage Score: 0.09\n",
      "Episode 900\tAverage Score: 0.10\n",
      "Episode 1000\tAverage Score: 0.12\n",
      "Episode 1100\tAverage Score: 0.16\n",
      "Episode 1200\tAverage Score: 0.19\n",
      "Episode 1300\tAverage Score: 0.23\n",
      "Episode 1400\tAverage Score: 0.20\n",
      "Episode 1500\tAverage Score: 0.28\n",
      "Episode 1600\tAverage Score: 0.36\n",
      "Episode 1700\tAverage Score: 0.33\n",
      "Episode 1800\tAverage Score: 0.42\n",
      "Episode 1900\tAverage Score: 0.40\n",
      "Episode 1956\tAverage Score: 0.51\n",
      "Environment solved in 1956 episodes!\tAverage Score: 0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# config = config()\n",
    "config.seed = 0\n",
    "config.buffer_size = int(1e5)\n",
    "config.batch_size = 512\n",
    "config.gamma = 0.99\n",
    "config.tau = 2e-1\n",
    "\n",
    "config.actor_hidden_sizes = [256, 128]\n",
    "config.lr_actor = 1e-4\n",
    "config.critic_hidden_sizes = [256, 128]\n",
    "config.lr_critic = 3e-4\n",
    "config.critic_weight_decay = 0.0\n",
    "\n",
    "config.mu = 0.\n",
    "config.theta = 0.15\n",
    "config.sigma = 0.2\n",
    "\n",
    "config.update_every = 5\n",
    "config.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# config.prioritized_replay = True\n",
    "config.beta = 0.4\n",
    "config.beta_decay = 10000\n",
    "# config.alpha = 0.6\n",
    "\n",
    "# print(config.batch_size)\n",
    "\n",
    "maddpg = MADDPG(state_size, action_size, config)\n",
    "# print(config)\n",
    "scores = train(maddpg, 3000, 2000)\n",
    "\n",
    "plot_scores(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
