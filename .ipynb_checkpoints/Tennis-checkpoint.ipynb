{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Tennis\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import config\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data.maddpg import MADDPG\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize the unity Tennis environment\n",
    "\n",
    "make sure the path to file_name is corrent and matching to your system. \n",
    "In here you should locate the Tennis environment file on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"/home/maurice/Documents/udacity_new/data/Tennis_Linux_NoVis/Tennis.x86_64\")\n",
    "# env = UnityEnvironment(file_name=\"/home/maurice/Documents/udacity_new/data/Tennis_Linux/Tennis.x86_64\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get default environment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name  = env.brain_names[0]\n",
    "brain       = env.brains[brain_name]\n",
    "env_info    = env.reset(train_mode=True)[brain_name]\n",
    "num_agents  = len(env_info.agents)\n",
    "action_size = brain.vector_action_space_size\n",
    "state_size  = env_info.vector_observations.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Set-up training algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(maddpg, n_eps=10000, max_steps=2000):\n",
    "    \n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    train_mode = True\n",
    "    \n",
    "#     frame_num = 0\n",
    "    current_max = 1.0\n",
    "\n",
    "    # training loop\n",
    "    for i_eps in range(n_eps):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "        state    = env_info.vector_observations\n",
    "        maddpg.reset()\n",
    "        agent_scores = np.zeros(num_agents)\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            action     = maddpg.act(state, 1.0)\n",
    "            env_info   = env.step(action)[brain_name] \n",
    "            reward     = env_info.rewards\n",
    "            next_state = env_info.vector_observations\n",
    "            done       = env_info.local_done\n",
    "            maddpg.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            state      = next_state\n",
    "            agent_scores += reward\n",
    "#             frame_num += 1\n",
    "            \n",
    "            if np.any(done): break\n",
    "                \n",
    "        max_score = np.max(agent_scores)\n",
    "        scores_window.append(max_score)\n",
    "        scores.append(max_score)                \n",
    "    \n",
    "        print('\\rTraining Episode: {}\\tAverage Score: {:.2f}'.format(i_eps, np.mean(scores_window)), end=\"\")\n",
    "        \n",
    "        if i_eps % 100 == 0:\n",
    "            print('\\rTraining Episode: {}\\tAverage Score: {:.2f}'.format(i_eps, np.mean(scores_window)))\n",
    "\n",
    "        if max_score > current_max:\n",
    "            current_max = max_score\n",
    "            for i in range(len(maddpg.agents)):\n",
    "                torch.save(maddpg.agents[i].actor.state_dict(),  'checkpoints/actor'  + str(i) +'checkpoint.pth')\n",
    "                torch.save(maddpg.agents[i].critic.state_dict(), 'checkpoints/critic' + str(i) +'checkpoint.pth')\n",
    "\n",
    "                \n",
    "        if np.mean(scores_window) >= 0.5:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_eps, np.mean(scores_window)))\n",
    "            break\n",
    "            \n",
    "            \n",
    "    return scores\n",
    "                \n",
    "    \n",
    "    \n",
    "def plot_scores(scores, title=\"\"):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(title)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Configure hyperparameters and perform training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup config datastruct with hyperparameters\n",
    "config.seed        = 1\n",
    "config.buffer_size = int(1e5)\n",
    "config.batch_size  = 512\n",
    "config.gamma       = 0.99\n",
    "config.tau         = 2e-1\n",
    "config.mu          = 0.0\n",
    "config.theta       = 0.15\n",
    "config.sigma       = 0.2\n",
    "config.beta        = 0.4\n",
    "config.beta_decay  = 10000\n",
    "\n",
    "config.action_size         = action_size\n",
    "config.state_size          = state_size\n",
    "config.num_agents          = num_agents\n",
    "config.actor_hidden_sizes  = [128, 64]\n",
    "config.critic_hidden_sizes = [128, 64]\n",
    "config.lr_actor            = 1e-4\n",
    "config.lr_critic           = 3e-4\n",
    "config.critic_weight_decay = 0.0\n",
    "config.update_every        = 5\n",
    "\n",
    "config.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Episode: 0\tAverage Score: 0.00\n",
      "Training Episode: 100\tAverage Score: 0.00\n",
      "Training Episode: 200\tAverage Score: 0.00\n",
      "Training Episode: 300\tAverage Score: 0.00\n",
      "Training Episode: 400\tAverage Score: 0.00\n",
      "Training Episode: 500\tAverage Score: 0.01\n",
      "Training Episode: 600\tAverage Score: 0.03\n",
      "Training Episode: 700\tAverage Score: 0.03\n",
      "Training Episode: 800\tAverage Score: 0.03\n",
      "Training Episode: 900\tAverage Score: 0.06\n",
      "Training Episode: 1000\tAverage Score: 0.10\n",
      "Training Episode: 1100\tAverage Score: 0.11\n",
      "Training Episode: 1200\tAverage Score: 0.10\n",
      "Training Episode: 1300\tAverage Score: 0.11\n",
      "Training Episode: 1400\tAverage Score: 0.09\n",
      "Training Episode: 1500\tAverage Score: 0.11\n",
      "Training Episode: 1600\tAverage Score: 0.11\n",
      "Training Episode: 1700\tAverage Score: 0.10\n",
      "Training Episode: 1800\tAverage Score: 0.12\n",
      "Training Episode: 1900\tAverage Score: 0.12\n",
      "Training Episode: 2000\tAverage Score: 0.13\n",
      "Training Episode: 2100\tAverage Score: 0.14\n",
      "Training Episode: 2200\tAverage Score: 0.16\n",
      "Training Episode: 2300\tAverage Score: 0.15\n",
      "Training Episode: 2400\tAverage Score: 0.15\n",
      "Training Episode: 2500\tAverage Score: 0.19\n",
      "Training Episode: 2600\tAverage Score: 0.22\n",
      "Training Episode: 2700\tAverage Score: 0.22\n",
      "Training Episode: 2800\tAverage Score: 0.25\n",
      "Training Episode: 2900\tAverage Score: 0.28\n",
      "Training Episode: 3000\tAverage Score: 0.29\n",
      "Training Episode: 3100\tAverage Score: 0.27\n",
      "Training Episode: 3200\tAverage Score: 0.29\n",
      "Training Episode: 3300\tAverage Score: 0.33\n",
      "Training Episode: 3400\tAverage Score: 0.45\n",
      "Training Episode: 3500\tAverage Score: 0.40\n",
      "Training Episode: 3600\tAverage Score: 0.45\n",
      "Training Episode: 3700\tAverage Score: 0.43\n",
      "Training Episode: 3800\tAverage Score: 0.49\n",
      "Training Episode: 3804\tAverage Score: 0.51\n",
      "Environment solved in 3804 episodes!\tAverage Score: 0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training took 0:28:55 [h:mm:ss]\n"
     ]
    }
   ],
   "source": [
    "# run training algorithm and plot results\n",
    "maddpg = MADDPG(config)\n",
    "tic    = time.perf_counter()\n",
    "scores = train(maddpg, 5000, 2000)\n",
    "toc    = time.perf_counter()\n",
    "\n",
    "plot_scores(scores)\n",
    "print('training took ' + str(datetime.timedelta(seconds=round(toc - tic))) + ' [h:mm:ss]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Watch a smart agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: Ran out of input\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maurice/anaconda3/envs/drlnd/lib/python3.6/site-packages/grpc/_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"/home/maurice/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\", line 26, in Exchange\n",
      "    return self.child_conn.recv()\n",
      "  File \"/home/maurice/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "EOFError: Ran out of input\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-704cf4c5db58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# close the no_vis environment and open visual environment to see results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# env.close()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/maurice/Documents/udacity_new/data/Tennis_Linux/Tennis.x86_64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name, worker_id, base_port, curriculum, seed, docker_training, no_graphics)\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0maca_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_academy_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrl_init_parameters_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mUnityTimeOutException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36msend_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnityInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrl_initialization_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrap_unity_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnityRLInput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnityOutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maca_param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# close the no_vis environment and open visual environment to see results\n",
    "env.close()\n",
    "env = UnityEnvironment(file_name=\"/home/maurice/Documents/udacity_new/data/Tennis_Linux/Tennis.x86_64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_smart_agent(trained_maddpg):\n",
    "\n",
    "    for i in range(3): \n",
    "        env_info = env.reset(train_mode=False)[brain_name]\n",
    "        state    = env_info.vector_observations\n",
    "        trained_maddpg.reset()\n",
    "        agent_scores = np.zeros(num_agents)\n",
    "        \n",
    "        while True:\n",
    "            action     = trained_maddpg.act(state, 0.0)\n",
    "            env_info   = env.step(action)[brain_name] \n",
    "            reward     = env_info.rewards\n",
    "            next_state = env_info.vector_observations\n",
    "            done       = env_info.local_done  \n",
    "            state      = next_state\n",
    "            agent_scores += reward\n",
    "            \n",
    "            if np.any(done): break\n",
    "        print(f' Max score = {np.max(agent_scores)}')\n",
    "        \n",
    "                \n",
    "# trained_maddpg = MADDPG(config)\n",
    "# trained_maddpg.load_checkpoints()\n",
    "# run_smart_agent(trained_maddpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
